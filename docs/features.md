## 3. Features

* user can define a grid in map-projected geographic Cartesian (northing/easting) coordinates provided in the form of a Digital Elevation Model (DEM) with arbitrary EPSG projection code (but has to be in northing/easting; lat/lon won't work), 
* the program will automatically extract the portion of the grid that overlaps with the given co-registered image pair, 
* for radar-coordinate imagery, the code uses radar orbit information plus DEM along with GDAL coordinate transformation to precisely map the geolocation and the motion velocity at each grid point (in map-projected geographic Cartesian coordinates) to the corresponding pixel index and pixel displacement (in image coordinates), where the imaging along-track (azimuth) and line-of-sight (slant range) unit vectors are precisely derived at each grid point
* for map-projected geographic Cartesian-coordinate (e.g. optical) imagery, the code uses map projection coordinate information of the image pair along with GDAL coordinate transformation to precisely map the geolocation and the motion velocity at each grid point (in map-projected geographic Cartesian coordinates) to the corresponding pixel index and pixel displacement (in image coordinates), where the imaging horizontal- and vertical-direction unit vectors are precisely derived at each grid point
* the map-projected geographic z-direction motion velocity is related to the x-direction (easting) and y-direction (northing) motion velocity using the slope parallel flow (or irrotational flow) assumption as well as inputs from the x/y-direction local surface slope maps (for radar only)
* return the range/azimuth (radar) or horizontal/vertical (optical) pixel indices in the image pair for each point on the user-defined grid (in northing/easting) using an input DEM. Real DEM is required for radar only; for optical images, a dummy DEM (all zero value) can be used for defining the grid
* return the downstream search pixel displacement (expected shift between the two images) using inputs from the reference motion velocity maps (e.g. previous annual mosaics) and the local surface slope maps (derived from a DEM for radar only; can be a dummy DEM of all zero value for optical), both of which must be provided in northing/easting directions on the same grid as the DEM
* return the matrix of conversion coefficients that can convert the fine pixel displacement between the two images (estimated with the autoRIFT Python module https://github.com/leiyangleon/autoRIFT) to motion velocity in geographic x- (easting) and y- (northing) coordinates
* the current version can be installed with the ISCE software (that supports both radar and Cartesian coordinates) or as a standalone Python module (Cartesian coordinates only)
* when used in combination with the autoRIFT Python module (https://github.com/leiyangleon/autoRIFT), Geogrid can be used for feature tracking between image pair over a grid defined in an arbitrary geographic Cartesian (northing/easting) coordinate projection
* outputs are returned in geocoded GeoTIFF image file format with the same EPSG projection code as input search grid
* spatially varying input maps of velocity search range (in units of m/yr), chip size minimum and maximum (in units of m), stable surface mask (boolean) can be handled, with corresponding output (in units of integer image pixels) returned at each grid point.
* **[NEW]** For feature tracking of optical images, the program now supports fetching optical images (Landsat-8 GeoTIFF and Sentinel-2 COG formats are included) as well as other inputs (e.g. DEM, slope, etc; all in GeoTIFF format) from either local machine or or remotely using [GDAL virtual file systems](https://gdal.org/user/virtual_file_systems.html) (e.g., `/vsicurl/https://...`). See the changes on the autoRIFT [commands](https://github.com/leiyangleon/autoRIFT). Geogrid will now always perform coregistration. For feature tracking of radar images, the program also supports fetching auxilliary inputs (e.g. DEM, slope, etc; all in GeoTIFF format) from either local machine or remotely.
